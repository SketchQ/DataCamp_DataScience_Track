{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson I \n",
    "\n",
    "## Uniformity\n",
    "\n",
    "In this chapter, we're looking at more advanced data cleaning problems, such as:\n",
    "\n",
    "* uniformatiy\n",
    "* Cross field validation\n",
    "* Dealing with missing data\n",
    "\n",
    "In chapter 1, we saw how out of range values are a common problem when cleaning data, and that when left untouched, can skew your analysis.\n",
    "\n",
    "* Out of range movie ratings\n",
    "* Subscription dates in the future\n",
    "\n",
    "**Uniformity:**\n",
    "\n",
    "| **Column** | **Unit** |\n",
    "|--------|------|\n",
    "| Temperature | ``32C`` **is also** ``89.7F`` |\n",
    "| Weight | ``70 kg`` **is also** ``11 st`` |\n",
    "| Data | ``26-11-2019`` **is also** ``26, Novemer, 2019`` |\n",
    "| Money | ``100$`` **is also** ``10763,90 Yen`` |\n",
    "\n",
    "\n",
    "**Example**\n",
    "\n",
    "```python\n",
    "temperatures = pd.read_csv('temperature.csv')   \n",
    "temperatures.head()\n",
    "```\n",
    "\n",
    "<img src='pictures/temperature.jpg' />\n",
    "\n",
    "Here's a dataset with average temperature data throughout the month of March in New York City. The dataset was collected from different sources with temperature data in Celsius and Fahrenheit merged together. We can see that unless a major climate event occurred, the final value (``62.6``)here is most likely Fahrenheit, not Celsius. \n",
    "\n",
    "Let's confirm the presence of these values visually:\n",
    "\n",
    "```python\n",
    "# Import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "# Create scatter plot\n",
    "plt.scatter(x= 'Date', y= 'Temperature', data= temperatures)\n",
    "# Create title, xlabel and ylabel\n",
    "plt.title('Temperature in Celsius March 2019 - NYC')\n",
    "plt.xlabel('Dates')\n",
    "plt.ylabel('Temperature in Celsius')\n",
    "# Show plot\n",
    "plt.show()\n",
    "```\n",
    "\n",
    "<img src='pictures/temperature1.jpg' />\n",
    "\n",
    "Notice these values here? They all must be fahrenheit!\n",
    "\n",
    "### Treating temperature data\n",
    "\n",
    "A simple web search returns the formula for converting Fahrenheit to Celsius. To convert our temperature data, we isolate all rows of ``temperature`` column where it is above **40** using the ``.loc()`` method. We chose **40** because it's a common sense maximum for Celsius temperatures in New York City. \n",
    "\n",
    "We then convert these values to Celsius using the formula, and reassign them to their respective Fahrenheit values in temperatures. \n",
    "\n",
    "We can make sure that our conversion was correct with an ``assert`` statement, by making sure the maximum value of temperature is less than **40**.\n",
    "\n",
    "```python\n",
    "temp_fh = temperatures.loc[temperatures['Temperature'] > 40, 'Temperature']\n",
    "temp_cels = (temp_fh - 32) * (5/9)\n",
    "temperatures.loc[temperatures['Temperature'] > 40, 'Temperature'] = temp_cels\n",
    "\n",
    "# Assert conversion is correct\n",
    "assert temperatures['Temperature'].max() < 40\n",
    "```\n",
    "\n",
    "#### Treating date data\n",
    "\n",
    "Here's another common uniformity problem with date data. This is a DataFrame called birthdays containing birth dates for a variety of individuals. It has been collected from a variety of sources and merged into one.\n",
    "\n",
    "```python\n",
    "birthdays.head()\n",
    "```\n",
    "\n",
    "<img src='pictures/birthdays.jpg' />\n",
    "\n",
    "Notice the dates here? The one in blue has the month, day, year format, whereas the one in orange has the month written out. The one in red is obviously an error, with what looks like a day day year format. We'll learn how to deal with that one as well.\n",
    "\n",
    "### Datetime Formatting\n",
    "\n",
    "``datetime`` is useful for representing dates\n",
    "\n",
    "| **Date** | **datetime format** |\n",
    "|------|-----------------|\n",
    "| 25-12-2019 | ``%d-%m-%Y`` |\n",
    "| December 25th 2019 | ``%c`` |\n",
    "| 12-25-2019 | ``%m-%d-%Y`` |\n",
    "|... | .... |\n",
    "\n",
    "``pandas.to_datetime()`` :\n",
    "* Can recognize most formats automatically\n",
    "* Sometimes fails with erroneous or unrecognazable formats\n",
    "\n",
    "You can treat these date inconsistencies easily by converting your date column to ``datetime``. We can do this in *pandas* with the ``.to_datetime()`` function. However this isn't enough and will most likely return an error.\n",
    "\n",
    "```python\n",
    "# Converts to datetime - but wont work!\n",
    "birthdays['Birthday'] = pd.to_datetime(birthdays['birthday'])\n",
    "```\n",
    "\n",
    "since we have dates in multiple formats, especially the weird *day/day/format* which triggers an error with months. Instead we set the ``infer_datetime_format`` argument to ``True``, and set ``errors=coerce``. This will infer the format and return missing value for dates that couldn't be identified and converted instead of a value error.\n",
    "\n",
    "```python\n",
    "# Will Work!\n",
    "birthdays['Birthday'] = pd.to_datetime(birthdays['Birthday'],\n",
    "                                        # Attempt to infer format of each date\n",
    "                                        infer_datetime_format=True,\n",
    "                                        # Returns NA for rows where conversion failed\n",
    "                                         errors='coerce')\n",
    "```\n",
    "\n",
    "This returns the birthday column with aligned formats, with the initial ambiguous format of *day day year*, being set to *NAT*, which represents missing values in *Pandas* for *datetime* objects.\n",
    "\n",
    "We can also convert the format of a datetime column using the ``dt.strftime()`` method, which accepts a datetime format of your choice. For example, here we convert the Birthday column to day month year, instead of year month day.\n",
    "\n",
    "```python\n",
    "birthdays['Birthday'] = birthdays['Birthday'].dt.strftime(\"%d-%m-%Y\")\n",
    "```\n",
    "\n",
    "### Treating ambigous date data\n",
    "\n",
    "However a common problem is having ambiguous dates with vague formats. For example, is this date value set in March or August? \n",
    "\n",
    "***Is ``2019-03-08`` in August or March?***\n",
    "\n",
    "Unfortunately there's no clear cut way to spot this inconsistency or to treat it. Depending on the size of the dataset and suspected ambiguities, \n",
    "\n",
    "* We can either convert these dates to NAs and deal with them accordingly.\n",
    "* if you have additional context on the source of your data, you can probably infer the format\n",
    "* If the majority of subsequent or previous data is of one format, you can probably infer the format as well. \n",
    "\n",
    "All in all, it is essential to properly understand where your data comes from, before trying to treat it, as it will make making these decisions much easier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "### Uniform currencies\n",
    "\n",
    "In this exercise and throughout this chapter, you will be working with a retail banking dataset stored in the ``banking`` DataFrame. The dataset contains data on the amount of money stored in accounts (``acct_amount``), their currency (``acct_cur``), amount invested (``inv_amount``), account opening date (``account_opened``), and last transaction date (``last_transaction``) that were consolidated from American and European branches.\n",
    "\n",
    "You are tasked with understanding the average account size and how investments vary by the size of account, however in order to produce this analysis accurately, you first need to unify the currency amount into dollars."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pandas as pd\n",
    "# Banking dataset\n",
    "banking = pd.read_csv('datasets/banking_dirty.csv')\n",
    "\n",
    "# WILL ONLY WORK ON DATACAMP WEBSITE\n",
    "\n",
    "# Find values of acct_cur that are equal to 'euro'\n",
    "acct_eu = banking['acct_cur'] == 'euro'\n",
    "\n",
    "# Convert acct_amount where it is in euro to dollars\n",
    "banking.loc[acct_eu, 'acct_amount'] = banking.loc[acct_eu, 'acct_amount'] * 1.1\n",
    "\n",
    "# Unify acct_cur column by changing 'euro' values to 'dollar'\n",
    "banking.loc[acct_eu, 'acct_cur'] = 'dollar'\n",
    "\n",
    "# Assert that only dollar currency remains\n",
    "assert banking['acct_cur'].unique() == 'dollar'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Uniform dates\n",
    "\n",
    "After having unified the currencies of your different account amounts, you want to add a temporal dimension to your analysis and see how customers have been investing their money given the size of their account over each year. The ``account_opened`` column represents when customers opened their accounts and is a good proxy for segmenting customer activity and investment over time.\n",
    "\n",
    "However, since this data was consolidated from multiple sources, you need to make sure that all dates are of the same format. You will do so by converting this column into a ``datetime`` object, while making sure that the format is inferred and potentially incorrect formats are set to missing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0   2018-02-09\n",
      "1   2019-02-28\n",
      "2   2018-04-25\n",
      "3   2017-07-11\n",
      "4   2018-05-14\n",
      "Name: account_opened, dtype: datetime64[ns]\n",
      "0     2018\n",
      "1     2019\n",
      "2     2018\n",
      "3     2017\n",
      "4     2018\n",
      "      ... \n",
      "95    2018\n",
      "96    2017\n",
      "97    2017\n",
      "98    2017\n",
      "99    2017\n",
      "Name: acct_year, Length: 100, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Print the header of account_opened\n",
    "print(banking['account_opened'].head())\n",
    "\n",
    "# Convert account_opened to datetime\n",
    "banking['account_opened'] = pd.to_datetime(banking['account_opened'],\n",
    "                                           # Infer datetime format\n",
    "                                           infer_datetime_format = True,\n",
    "                                           # Return missing value for error\n",
    "                                           errors = 'coerce') \n",
    "\n",
    "# Get year of account opened\n",
    "banking['acct_year'] = banking['account_opened'].dt.strftime('%Y')\n",
    "\n",
    "# Print acct_year\n",
    "print(banking['acct_year'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson II\n",
    "\n",
    "## Cross field validation\n",
    "\n",
    "In this lesson we'll talk about cross field validation for diagnosing dirty data.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "\n",
    "flights = pd.read_csv('flights.csv')\n",
    "flights.head()\n",
    "```\n",
    "\n",
    "<img src='pictures/flights.jpg' />\n",
    "\n",
    "Let's take a look at the following dataset. It contains flight statistics on the total number of passengers in economy, business and first class as well as the total passengers for each flight. We know that these columns have been collected and merged from different data sources, and a common challenge when merging data from different sources is data integrity, or more broadly making sure that our data is correct.\n",
    "\n",
    "**Cross Field Validation:**\n",
    "\n",
    "* *The use of **multiple** fields in a dataset to sanity check data integrity*\n",
    "\n",
    "For example in our flights dataset, this could be summing *economy, business and first class* values and making sure they are equal to the *total passengers* on the plane. This could be easily done in Pandas;\n",
    "\n",
    "```python\n",
    "sum_classes = flights[['economy_class', 'business_class', 'first_class']].sum(axis=1)\n",
    "passenger_equ = sum_classes == flights['total_passengers']\n",
    "# Find and filter out rows with inconsistent passenger totals\n",
    "inconsistent_pass = flights[~passenger_equ]\n",
    "consistent_pass = flights[passenger_equ]\n",
    "```\n",
    "\n",
    "by first subsetting on the columns to ``.sum()``, then using the sum method with the ``axis`` argument set to ``1`` to indicate row wise summing. \n",
    "\n",
    "We then find instances where the total passengers column is equal to the sum of the classes. And find and filter out instances of inconsistent passenger amounts by subsetting on the equality we created with brackets and the tilde symbol.\n",
    "\n",
    "<img src='pictures/crossfield.jpg' />\n",
    "\n",
    "Here's another example containing *user IDs, birthdays and age* values for a set of *users*. We can for example make sure that the age and birthday columns are correct by subtracting the number of years between today's date and each birthday.\n",
    "\n",
    "```python\n",
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "# Convert to datetime and get today's date\n",
    "users['Birthday'] = pd.to_datetime(users['Birthday'])\n",
    "today = dt.date.today()\n",
    "# For each row in the Birthday column, calculate year difference\n",
    "age_manual = today.year - users['Birthday'].dt.year\n",
    "# Find instances where ages match\n",
    "age_equ = age_manual == users['Age']\n",
    "# Find and filter out rows with inconsistent age\n",
    "inconsistent_age = users[~age_equ]\n",
    "consistent_age = users[age_equ]\n",
    "```\n",
    "\n",
    "We can do this by first making sure the ``Birthday`` column is converted to ``datetime`` with the *pandas* to ``datetime`` function. \n",
    "\n",
    "We then create an *object* storing today's date using the datetime package's ``date.today()`` function. \n",
    "\n",
    "We then calculate the difference in years between today's date's year, and the year of each birthday by using the ``.dt.year`` attribute of the user's ``Birthday`` column. \n",
    "\n",
    "We then find instances where the calculated ages are equal to the actual age column in the users DataFrame. \n",
    "\n",
    "We then find and filter out the instances where we have inconsistencies using subsetting with brackets and the tilde symbol on the equality we created.\n",
    "\n",
    "### What to do when we catch inconsistencies?\n",
    "\n",
    "So what should be the course of action in case we spot inconsistencies with cross-field validation? Just like other data cleaning problems, there is no one size fits all solution, as often the best solution requires an in depth understanding of our dataset.\n",
    "\n",
    "* Dropping data\n",
    "* Set to missing and impute\n",
    "* Apply rules from domain knowledge\n",
    "\n",
    "All these routes and assumptions can be decided upon only when you have a good understanding of where your dataset comes from and the different sources feeding into it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "### How's our data integrity?\n",
    "\n",
    "New data has been merged into the ``banking`` DataFrame that contains details on how investments in the ``inv_amount`` column are allocated across four different funds *A, B, C and D*.\n",
    "\n",
    "Furthermore, the age and birthdays of customers are now stored in the ``age`` and ``birth_date`` columns respectively.\n",
    "\n",
    "You want to understand how customers of different age groups invest. However, you want to first make sure the data you're analyzing is correct. You will do so by cross field checking values of ``inv_amount`` and ``age`` against the amount invested in different funds and customers' birthdays. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inconsistent investments:  8\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import datetime as dt \n",
    "\n",
    "# Store fund columns to sum against\n",
    "fund_columns = ['fund_A', 'fund_B', 'fund_C', 'fund_D']\n",
    "\n",
    "# Find rows where fund_columns row sum == inv_amount\n",
    "inv_equ = banking[fund_columns].sum(axis= 1) == banking['inv_amount']\n",
    "\n",
    "# Store consistent and inconsistent data\n",
    "consistent_inv = banking[inv_equ]\n",
    "inconsistent_inv = banking[~inv_equ]\n",
    "\n",
    "# Store consistent and inconsistent data\n",
    "print(\"Number of inconsistent investments: \", inconsistent_inv.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of inconsistent ages:  100\n"
     ]
    }
   ],
   "source": [
    "# Store today's date and find ages\n",
    "today = dt.date.today()\n",
    "banking['birth_date'] = pd.to_datetime(banking['birth_date'])\n",
    "ages_manual = today.year - banking['birth_date'].dt.year\n",
    "\n",
    "# Find rows where age column == ages_manual\n",
    "age_equ = banking['Age'] == ages_manual\n",
    "\n",
    "# Store consistent and inconsistent data\n",
    "consistent_ages = banking[age_equ]\n",
    "inconsistent_ages = banking[~age_equ]\n",
    "\n",
    "# Store consistent and inconsistent data\n",
    "print(\"Number of inconsistent ages: \", inconsistent_ages.shape[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4c59e6e5379e7fd956ce48a476e9664867cfb6229c9530fa6fd87fb84f21040f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
