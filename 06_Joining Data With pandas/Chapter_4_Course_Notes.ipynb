{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Chapter IV\n",
    "\n",
    "### Using merge_ordered()\n",
    "\n",
    "This method can merge time-series and other ordered data.\n",
    "\n",
    "<img src='pictures\\merge_ordered.png' alt='merge_ordered' width=750 />\n",
    "\n",
    "We can see the output of the merge when we merge on the 'C' column. The results are similiar to the standart merge method with an outer join, but here that the results are sorted.\n",
    "\n",
    "#### Method comparison\n",
    "\n",
    "<img src='pictures\\Method_comparison.png' alt='comparison' width=750 />\n",
    "\n",
    "It has many of the same arguments we have already covered with the merge method. They both contain arguments to allow us to merge two tables on different columns. Both methods support different types of joins. Although, the **default for the merge method is \"inner\", it is \"outer\" for merge_order method.** Also, both methods support suffixes for overlapping column names. However, **how you call each of the methods is different**. Earlier in the course, we called the merge method by first listing a table and calling the method afterward. For merge_ordered(), you'll need to first call **pandas** then merge_ordered().\n",
    "\n",
    "#### Stock Data\n",
    "\n",
    "In this chapter, we will be working with financial, macroeconomic, and stock market data.\n",
    "\n",
    "<img src='pictures\\Stock_data.png' alt='stock' width=700 />\n",
    "\n",
    "We have a table of the stock prices of the Apple corporation from February to June 2007. We also have a table of the stock price for McDonald's corporation from January to May 2007, and we want to merge them.\n",
    " \n",
    "```python\n",
    "import pandas as pd\n",
    "pd.merge_orderd(aapl, mcd, on='date', suffixes=('_aapl', '_mcd'))\n",
    "```\n",
    "\n",
    "<img src='pictures\\Merging_data.png' alt='merging' width=500 />\n",
    "\n",
    "The first two arguments are the left and right tables. We set the **\"on\"** argument equal to date. Finally, we set the **suffixes** argument to determine which table the data originated. This results in a table **sorted by date**. There **isn't** a value for Apple in January or a value for McDonald's for June since values for these time periods are not available in the two original tables.\n",
    "\n",
    "#### Forward Fill\n",
    "\n",
    "We can fill in this missing data using a technique called forward filling. It will interpolate missing data by filling the missing values with the previous value.\n",
    "\n",
    "```python\n",
    "pd.merge_ordered(aapl, mcd, on='date', suffixes=('_aapl', '_mcd'), fill_method='ffill')\n",
    "```\n",
    "\n",
    "<img src='pictures\\Forward_fill.png' alt='example' width=500 />\n",
    "\n",
    "In the result, notice that the missing value for McDonald's in the last row is now filled in with the row before it. Apple in the first row is still missing since there isn't a row before the first row to copy into the missing value for Apple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GDP</th>\n",
       "      <th>Returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>GDP</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.040669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Returns</th>\n",
       "      <td>0.040669</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              GDP   Returns\n",
       "GDP      1.000000  0.040669\n",
       "Returns  0.040669  1.000000"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Exercise I\n",
    "# Correlation between GDP and S&P500\n",
    "\n",
    "# DataFrames sp500, gdp\n",
    "import pandas as pd\n",
    "sp500 = pd.read_csv('datasets\\\\S&P500.csv')\n",
    "gdp = pd.read_csv('datasets\\\\WorldBank_GDP.csv')\n",
    "\n",
    "# User merge_orderd() to merge gdp and sp500 on year and date\n",
    "gdp_sp500 = pd.merge_ordered(gdp, sp500, left_on='Year', right_on='Date', how='left', fill_method='ffill')\n",
    "\n",
    "\n",
    "# Subset the gdp and returns columns\n",
    "gdp_returns = gdp_sp500[['GDP', 'Returns']]\n",
    "\n",
    "# Print gdp_returns correlation\n",
    "gdp_returns.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using merge_asof()\n",
    "\n",
    "* Similar to a ```merge_ordered()``` left join\n",
    "    - Similar features as ```merge_ordered()```\n",
    "* Match on the nearest key column and not exact matches.\n",
    "    - Merged 'on' column must be sorted.\n",
    "\n",
    "\n",
    "<img src='pictures\\Merged_asof.png' width=500 />\n",
    "\n",
    "The **merge_asof()** method is similar to an **ordered left join**. It has similar features as **merge_ordered()**. However, unlike an ordered left join, merge_asof() will match on the **nearest value columns rather than equal values**. This brings up an important point - whatever columns you merge on **must be sorted**. In the table shown here, when we merge on column \"C\", we bring back all of the rows from the left table.\n",
    "\n",
    "#### DataSets\n",
    "\n",
    "For this example, we will look at merging two tables. The first is stock price data for the **Visa** company with entries for **every hour** on Nov, 11, 2017. The second table is **IBM** stock prices on the same day with entries for **roughly every five minutes**.\n",
    "\n",
    "<img src='pictures\\Tables.png' width=700 />\n",
    "\n",
    "Let's use merge_asof() to merge the tables. The input arguments are very similar to what we have already seen in the course. Here we list the left and right tables first. Then we define that we want to merge on the \"date_time\" column. Finally, we provide a set of suffixes. Our output is similar to a left join, so we see all of the rows from the left Visa table. However, the values from the IBM table are based on how close the date_time values match with the Visa table. \n",
    "\n",
    "```python\n",
    "pd.merge_asof(visa, ibm, on='date_time', suffixes=('_visa', '_ibm'))\n",
    "```\n",
    "\n",
    "<img src='pictures\\asof.png' width=500 />\n",
    "\n",
    "Notice the first row and the IBM price of 149.11. Let's show the IBM table again and see why this value was chosen in the merger. It comes from the row indexed as 4. This row has the closest date_time that is less than the date_time in the Visa table.\n",
    "\n",
    "#### merge_asof() example with direction\n",
    "\n",
    "This time in our merge_asof() method, we list the **direction argument** as \"forward\". This will change the behavior of the method to select the first row in the right table whose \"on\" key column is greater than or equal to the left's key column. The **default value** for the direction argument is **\"backward\"**.\n",
    "\n",
    "```python\n",
    "pd.merge_asof(visa, ibm, on=['date_time'], suffixes=('_visa', '_ibm'), direction='forward')\n",
    "```\n",
    "\n",
    "<img src='pictures\\asof_direction.png' width=500 />\n",
    "\n",
    "When we look at our results, we see different values for the IBM column. Let's again look at the first IBM value and trace it back to the IBM table. We see it in the row indexed as 5. Its date_time is slightly greater than the date_time in the visa table.\n",
    "Finally, you can set the **direction argument to \"nearest\"** which returns the nearest row in the right table regardless if it is forward or backwards."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selecting data with .query()\n",
    "\n",
    "Now that you have learned quite a bit about combining data from different data sources, let's review a pandas method for selecting data from the table called the query() method. pandas provides many methods for selecting data, and query() is one of them.\n",
    "\n",
    "```python\n",
    ".query('SOME SELECTION STATEMENT')\n",
    "```\n",
    "\n",
    "* Accepts an input string\n",
    "    - Input string used to determine what rows are returned\n",
    "    - Input string similar to statement after **WHERE** clause in **SQL** statement\n",
    "        - **Prior knowledge of SQL is not necessary**\n",
    "\n",
    "\n",
    "#### Querying on a single condition\n",
    "\n",
    "We have the following table named stocks with the stock price of Disney and Nike on different days. Now imagine we would like to select the rows where Nike is equal to or above 90.\n",
    "\n",
    "<img src='pictures\\stocks.png' width=450 />\n",
    "\n",
    "---\n",
    "\n",
    "```python\n",
    "stocks.query('nike >= 90')\n",
    "```\n",
    "The method returns all rows in stocks where Nike is greater than or equal to 90.\n",
    "\n",
    "<img src='pictures\\nike_90.png' width=450 />\n",
    "\n",
    "---\n",
    "\n",
    "#### Querying on a multiple conditions, \"and\", \"or\"\n",
    "\n",
    "```python\n",
    "stocks.query('nike > 90 and disney < 140')\n",
    "\n",
    "stocks.query('nike > 96 or disney < 98')\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "#### Using .query() to select text\n",
    "\n",
    "```python\n",
    "stocks_long.query('stock == \"disney\" or (stock == \"nike\" and close < 90)')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reshaping data with .melt()\n",
    "\n",
    "This method will unpivot a table from wide to long format. This is often a much more computer-friendly format.\n",
    "\n",
    "| Wide      | Long  |\n",
    "| :------:  |:----:|\n",
    "| <img src='pictures\\wide.png' width=250 /> | <img src='pictures\\long.png' width=250 /> |    \n",
    "\n",
    "The melt method will allow us to unpivot, or change the format of, our dataset. In this image, we change the height and weight columns from their wide horizontal placement to a long vertical placement.\n",
    "\n",
    "<img src='pictures\\melt.png' width=500 />\n",
    "\n",
    "#### Dataset in wide format\n",
    "\n",
    "To demonstrate the melt method, let's start with this dataset of financial metrics of two popular social media companies. Notice that the years are horizontal. Let's change them so that they are vertically placed.\n",
    "\n",
    "<div><p style=\"float: left;\"><img src='pictures\\social_fin.png' width=500></p>\n",
    "<p> this table is called <code>social_fin</code></p>\n",
    "</div>\n",
    "<div style=\"clear: left;\"></div>\n",
    "\n",
    "#### Example of .melt()\n",
    "\n",
    "```python\n",
    "social_fin_tall = social_fin.melt(id_vars=['financial', 'company'])\n",
    "social_fin_tall.head(10)\n",
    "```\n",
    "\n",
    "<img src='pictures\\social_fin_tall.png' width=500 />\n",
    "\n",
    "Here we call the **melt()** method on the table ```social_fin```. The first input argument to the method is **id_vars**. These are columns to be used as **identifier variables**. We can also think of them as columns in our original dataset that we do not want to change. In our output, we print the first ten rows. Our years are listed vertically. Our final column now has all of our values in one column versus multiple columns. Again, this is a much more computer-friendly format than our original table. We unpivoted each of the separate columns 2016 through 2019. Our output has data for every year in our starting table, but again, we are only showing the first couple of rows. In the next example, we will look at how to control what columns are unpivoted.\n",
    "\n",
    "#### Melting with value_vars\n",
    "\n",
    "```python\n",
    "social_fin_tall = social_fin.melt(id_vars=['financial', 'company'],\n",
    "                                    value_vars=['2018', '2017'])\n",
    "```\n",
    "\n",
    "<img src='pictures\\value_vars.png' width=500 />\n",
    "\n",
    "This time, let's use the argument **value_vars** with the **melt()** method. This argument will allow us to control which columns are unpivoted. Here, we unpivot only the **2018 and 2017** columns. Our output now **only** has data for the years 2018 and 2017. Additionally, the **order** of the value_var was kept. The output starts with 2018, then moves to 2017. Finally, notice that the column with the years is now named variable, and our values column is named value. We will adjust that in our next example.\n",
    "\n",
    "#### Melting with column names\n",
    "\n",
    "```python\n",
    "social_fin_tall = social_fin.melt(id_vars=['financial', 'company'],\n",
    "                                    value_vars=['2018', '2017'],\n",
    "                                    var_name=['year'], value_name='dollars')\n",
    "```\n",
    "\n",
    "<img src='pictures\\column_names.png' width=500 />\n",
    "\n",
    "In this example, we have added some additional inputs to our **melt()** method. The **var_name** argument will allow us to set the name of the year **column** in the output. Similarly, the **value_name** argument will allow us to set the name of the **value column** in the output. It is the same as before, except our variable and value columns are renamed year and dollars, respectively. \n",
    "\n",
    "We have seen how the melt() method is useful for reshaping our tables. Imagine a situation where you have merged many columns, making your table very wide. The merge() method can then be used to reshape that table into a more computer-friendly format."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4c59e6e5379e7fd956ce48a476e9664867cfb6229c9530fa6fd87fb84f21040f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
