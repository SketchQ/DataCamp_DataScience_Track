{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter II : Aggregating DataFrames\n",
    "\n",
    "## Summary Statistics\n",
    "\n",
    "Summary statistics, as follows from their name, are numbers that summarize and tell you about your dataset\n",
    "\n",
    "### Summarizing Numerical Data\n",
    "\n",
    "* Mean: The average of all the values in a column\n",
    "* Median: The middle value of a column\n",
    "* Mode: The most common value in a column\n",
    "* Min: The lowest value in a column\n",
    "* Max: The highest value in a column\n",
    "* Variance: The average of the squared differences between each value in a column and the mean\n",
    "* Standard Deviation: The square root of the variance\n",
    "* sum: The sum of all the values in a column\n",
    "* quantile: The value in a column that is closest to a given percentile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt \n",
    "import numpy as np \n",
    "\n",
    "dogs = pd.read_csv('datasets\\\\Dogs.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49.714285714285715"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summarizing numerical data\n",
    "\n",
    "dogs['Height(cm)'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2011-12-11'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Oldest Dog\n",
    "dogs[' Date of Birth '].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2018-02-27'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Youngest Dog\n",
    "dogs[' Date of Birth '].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21.0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The .agg() method\n",
    "# This method allows you to compute custom summary statistics.\n",
    "\n",
    "def pct30(column):\n",
    "    return column.quantile(0.3)\n",
    "\n",
    "dogs[' Weight (kg)'].agg(pct30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " Weight (kg)    21.0\n",
       "Height(cm)      45.4\n",
       "dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Summaries on multiple columns\n",
    "# .agg() can also be used on multiple columns\n",
    "\n",
    "dogs[[' Weight (kg)', 'Height(cm)']].agg(pct30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pct30    21.0\n",
       "pct40    22.4\n",
       "Name:  Weight (kg), dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Multiple Summaries\n",
    "# We can also use .agg() to get multiple summary statistics at once.\n",
    "\n",
    "def pct40(column):\n",
    "    return column.quantile(0.4)\n",
    "\n",
    "dogs[' Weight (kg)'].agg([pct30, pct40])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cumulative Sum\n",
    "\n",
    "pandas also has methods for computing cumulative statistics, for example cumulative sum.  \n",
    "Calling cumsum on a column returns not just one number, but a number for each row of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    25\n",
       "1    23\n",
       "2    22\n",
       "3    17\n",
       "4    29\n",
       "5     2\n",
       "6    74\n",
       "Name:  Weight (kg), dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Weight Column\n",
    "dogs[' Weight (kg)']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     25\n",
       "1     48\n",
       "2     70\n",
       "3     87\n",
       "4    116\n",
       "5    118\n",
       "6    192\n",
       "Name:  Weight (kg), dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cumulative sum of Weight Column\n",
    "dogs[' Weight (kg)'].cumsum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cummulative Statistics\n",
    "\n",
    "* .cummax() : The maximum value of a column, for each row, starting from the first row\n",
    "* .cummin() : The minimum value of a column, for each row, starting from the first row\n",
    "* .cumprod() : The product of all values in a column, for each row, starting from the first row\n",
    "\n",
    "These all return an entire column of a DataFrame, rather than a single number.\n",
    "\n",
    "### Walmart\n",
    "\n",
    "In this Chapter we'll be working with data on Walmart stores, which is a chain of department stores in the US. The dataset contains weekly sales in US dollars in various stores. Each store has an ID number and a specific store type. The sales are also separated by department ID. Along with weekly sales, there is information about whether it was a holiday week or not, the average temperature during the week in that location, the average fuel price in dollars per liter that week, and the national unemployment rate that week."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  store type  department        date  weekly_sales  is_holiday  \\\n",
      "0           0      1    A           1  2010-02-05      24924.50       False   \n",
      "1           1      1    A           1  2010-03-05      21827.90       False   \n",
      "2           2      1    A           1  2010-04-02      57258.43       False   \n",
      "3           3      1    A           1  2010-05-07      17413.94       False   \n",
      "4           4      1    A           1  2010-06-04      17558.09       False   \n",
      "\n",
      "   temperature_c  fuel_price_usd_per_l  unemployment  \n",
      "0       5.727778              0.679451         8.106  \n",
      "1       8.055556              0.693452         8.106  \n",
      "2      16.816667              0.718284         7.808  \n",
      "3      22.527778              0.748928         7.808  \n",
      "4      27.050000              0.714586         7.808  \n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10774 entries, 0 to 10773\n",
      "Data columns (total 10 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   Unnamed: 0            10774 non-null  int64  \n",
      " 1   store                 10774 non-null  int64  \n",
      " 2   type                  10774 non-null  object \n",
      " 3   department            10774 non-null  int64  \n",
      " 4   date                  10774 non-null  object \n",
      " 5   weekly_sales          10774 non-null  float64\n",
      " 6   is_holiday            10774 non-null  bool   \n",
      " 7   temperature_c         10774 non-null  float64\n",
      " 8   fuel_price_usd_per_l  10774 non-null  float64\n",
      " 9   unemployment          10774 non-null  float64\n",
      "dtypes: bool(1), float64(4), int64(3), object(2)\n",
      "memory usage: 768.2+ KB\n",
      "None\n",
      "23843.950148505668\n",
      "12049.064999999999\n"
     ]
    }
   ],
   "source": [
    "wallmart_df = pd.read_csv('datasets\\\\sales_subset.csv')\n",
    "\n",
    "# Print the head of the wallmart_df DataFrame\n",
    "print(wallmart_df.head())\n",
    "\n",
    "# Print the info about the wallmart_df DataFrame\n",
    "print(wallmart_df.info())\n",
    "\n",
    "# Print the mean of weekly_sales\n",
    "print(wallmart_df['weekly_sales'].mean())\n",
    "\n",
    "# Print the median of weekly_sales\n",
    "print(wallmart_df['weekly_sales'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012-10-26\n",
      "2012-10-26\n"
     ]
    }
   ],
   "source": [
    "# Print the maximum of the date column\n",
    "print(wallmart_df['date'].max())\n",
    "\n",
    "# print the minumum of the date column\n",
    "print(wallmart_df['date'].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16.583333333333336\n",
      "        temperature_c  fuel_price_usd_per_l  unemployment\n",
      "iqr         16.583333              0.073176         0.565\n",
      "median      16.966667              0.743381         8.099\n"
     ]
    }
   ],
   "source": [
    "# Import numpy and create custom IQR function\n",
    "def iqr(column):\n",
    "    return column.quantile(0.75) - column.quantile(0.25)\n",
    "\n",
    "# Print IQR of the temperature_c column\n",
    "print(wallmart_df['temperature_c'].agg(iqr))\n",
    "\n",
    "# Update to print IQR of temperature_c, fuel_price_usd_per_l, & unemployment\n",
    "print(wallmart_df[['temperature_c', 'fuel_price_usd_per_l', 'unemployment']].agg([iqr,np.median]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counting\n",
    "\n",
    "Imagine a DataFrame that contains vet visits. The vet's office wants to know how many dogs of each breed have visited their office. However, some dogs have been to the vet more than once, so we can't just count the number of each breed in the breed column.\n",
    "\n",
    "### Dropping duplicate names\n",
    "\n",
    "Let's try to fix this by removing rows that contain a dog name already listed earlier in the dataset, or in other words; we'll extract a dog with each name from the dataset once.  \n",
    "We can do this by using the **drop_duplicates()** method.\n",
    "\n",
    "```python\n",
    "vet_visits.drop_duplicates(subset=['Name'])\n",
    "```\n",
    "\n",
    "It takes and argument, subset, which is the column we want to find our duplicates based on.  \n",
    "Because we have two different dogs with the same name, we'll need to consider more than just name when dropping duplicates.\n",
    "\n",
    "### Dropping Duplicate pairs\n",
    "\n",
    "To base our duplicate dropping on multiple columns, we can pass a list of column names to the subset argument, in this case, name and breed.\n",
    "\n",
    "```python\n",
    "unique_dogs = vet_visits.drop_duplicates(subset=['Name', 'Breed'])\n",
    "```\n",
    "\n",
    "### Easy as 1, 2, 3\n",
    "\n",
    "To count the dogs of each breed, we'll subset the breed column and use the **value_count** method.  \n",
    "We can also use the **sort** argument to get the breeds with the biggest counts on top.\n",
    "\n",
    "```python\t\n",
    "unique_dogs['Breed'].value_counts()\n",
    "```\n",
    "\n",
    "or with the **sort** argument\n",
    "\n",
    "```python\n",
    "unique_dogs['Breed'].value_counts(sort=True)\n",
    "```\n",
    "\n",
    "### Proportion\n",
    "\n",
    "The normalize argument can bu used to turn the counts into proportions of the total.  \n",
    "%25 of the dogs that go to this vet are Labrador Retrievers.\n",
    "\n",
    "```python\n",
    "unique_dogs['Breed'].value_counts(normalize=True)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Unnamed: 0  store type  department        date  weekly_sales  \\\n",
      "0              0      1    A           1  2010-02-05      24924.50   \n",
      "901          901      2    A           1  2010-02-05      35034.06   \n",
      "1798        1798      4    A           1  2010-02-05      38724.42   \n",
      "2699        2699      6    A           1  2010-02-05      25619.00   \n",
      "3593        3593     10    B           1  2010-02-05      40212.84   \n",
      "\n",
      "      is_holiday  temperature_c  fuel_price_usd_per_l  unemployment  \n",
      "0          False       5.727778              0.679451         8.106  \n",
      "901        False       4.550000              0.679451         8.324  \n",
      "1798       False       6.533333              0.686319         8.623  \n",
      "2699       False       4.683333              0.679451         7.259  \n",
      "3593       False      12.411111              0.782478         9.765  \n",
      "    Unnamed: 0  store type  department        date  weekly_sales  is_holiday  \\\n",
      "0            0      1    A           1  2010-02-05      24924.50       False   \n",
      "12          12      1    A           2  2010-02-05      50605.27       False   \n",
      "24          24      1    A           3  2010-02-05      13740.12       False   \n",
      "36          36      1    A           4  2010-02-05      39954.04       False   \n",
      "48          48      1    A           5  2010-02-05      32229.38       False   \n",
      "\n",
      "    temperature_c  fuel_price_usd_per_l  unemployment  \n",
      "0        5.727778              0.679451         8.106  \n",
      "12       5.727778              0.679451         8.106  \n",
      "24       5.727778              0.679451         8.106  \n",
      "36       5.727778              0.679451         8.106  \n",
      "48       5.727778              0.679451         8.106  \n",
      "498     2010-09-10\n",
      "691     2011-11-25\n",
      "2315    2010-02-12\n",
      "6735    2012-09-07\n",
      "6810    2010-12-31\n",
      "6815    2012-02-10\n",
      "6820    2011-09-09\n",
      "Name: date, dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Drop duplicate store/type combinations\n",
    "store_types = wallmart_df.drop_duplicates(subset=['store', 'type'])\n",
    "print(store_types.head())\n",
    "\n",
    "# Drop duplicate store/department combinations\n",
    "store_depts = wallmart_df.drop_duplicates(subset=['store', 'department']) \n",
    "print(store_depts.head())\n",
    "\n",
    "# Subset the rows where is_holiday is True and drop duplicate dates\n",
    "holiday_dates = wallmart_df[wallmart_df['is_holiday'] == True].drop_duplicates(subset='date')\n",
    "\n",
    "# Print date col of holiday_dates\n",
    "print(holiday_dates['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A    11\n",
      "B     1\n",
      "Name: type, dtype: int64\n",
      "A    0.916667\n",
      "B    0.083333\n",
      "Name: type, dtype: float64\n",
      "1     12\n",
      "55    12\n",
      "72    12\n",
      "71    12\n",
      "67    12\n",
      "      ..\n",
      "37    10\n",
      "48     8\n",
      "50     6\n",
      "39     4\n",
      "43     2\n",
      "Name: department, Length: 80, dtype: int64\n",
      "1     0.012917\n",
      "2     0.012917\n",
      "3     0.012917\n",
      "4     0.012917\n",
      "5     0.012917\n",
      "        ...   \n",
      "95    0.012917\n",
      "96    0.012917\n",
      "97    0.012917\n",
      "98    0.012917\n",
      "99    0.011841\n",
      "Name: department, Length: 80, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Count the number of stores of each type\n",
    "store_counts = store_types['type'].value_counts()\n",
    "print(store_counts)\n",
    "\n",
    "# get the proportion of stores of each type\n",
    "store_props = store_types['type'].value_counts(normalize=True)\n",
    "print(store_props)\n",
    "\n",
    "# Count the number of each department number and sort \n",
    "dept_counts_sorted = store_depts['department'].value_counts(sort=True)\n",
    "print(dept_counts_sorted)\n",
    "\n",
    "# Get the proportion of departments of each number and sort \n",
    "dept_props_sorted = store_depts['department'].value_counts(sort=True, normalize=True)\n",
    "print(dept_props_sorted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouped Summary Statistics\n",
    "\n",
    "While computing summary statistics of entire columns may be useful, you can gain many insights from summaries of individual groups. For example, does one color of dog weigh more than another on avarage? Are female dogs taller than males?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Colour\n",
      "Black    26.0\n",
      "Brown    23.5\n",
      "Gray     17.0\n",
      "Tan       2.0\n",
      "White    74.0\n",
      "Name:  Weight (kg), dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Summaries by group\n",
    "\n",
    "dogs[dogs['Colour'] == 'Black'] [' Weight (kg)'].mean()\n",
    "dogs[dogs['Colour'] == 'Brown'] [' Weight (kg)'].mean()\n",
    "dogs[dogs['Colour'] == 'White'] [' Weight (kg)'].mean()\n",
    "dogs[dogs['Colour'] == 'Gray'] [' Weight (kg)'].mean()\n",
    "dogs[dogs['Colour'] == 'Tan'] [' Weight (kg)'].mean()\n",
    "\n",
    "# But this too cumbersome and we can do it with just one line\n",
    "print(dogs.groupby('Colour')[' Weight (kg)'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's where **groupby** method comes in. We can group by the color variable, select the weight column, and take the mean. This will give us the mean weight for each dog color.  \n",
    "Just like with ungrouped summary statistics, we can use the **agg** method to get multiple statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>sum</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Colour</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Black</th>\n",
       "      <td>23</td>\n",
       "      <td>29</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Brown</th>\n",
       "      <td>22</td>\n",
       "      <td>25</td>\n",
       "      <td>47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gray</th>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tan</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        min  max  sum\n",
       "Colour               \n",
       "Black    23   29   52\n",
       "Brown    22   25   47\n",
       "Gray     17   17   17\n",
       "Tan       2    2    2\n",
       "White    74   74   74"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here, we pass a list of functions into agg after grouping by color.\n",
    "\n",
    "dogs.groupby('Colour')[' Weight (kg)'].agg([min, max, sum])\n",
    "\n",
    "# This gives the minumum, maximum and sum of the different colored dogs' weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also group by multiple columns and calculate summary statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Colour  Breed      \n",
       "Black   Labrador       29\n",
       "        Poodle         23\n",
       "Brown   Labrador       25\n",
       "        Poodle         22\n",
       "Gray    Schnauzer      17\n",
       "Tan     Chihuahua       2\n",
       "White   St. Bernard    74\n",
       "Name:  Weight (kg), dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here, we group by color and breed, select the weight column and take the mean.\n",
    "\n",
    "dogs.groupby(['Colour', 'Breed'])[' Weight (kg)'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Weight (kg)</th>\n",
       "      <th>Height(cm)</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Colour</th>\n",
       "      <th>Breed</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Black</th>\n",
       "      <th>Labrador</th>\n",
       "      <td>29</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Poodle</th>\n",
       "      <td>23</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Brown</th>\n",
       "      <th>Labrador</th>\n",
       "      <td>25</td>\n",
       "      <td>56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Poodle</th>\n",
       "      <td>22</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Gray</th>\n",
       "      <th>Schnauzer</th>\n",
       "      <td>17</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tan</th>\n",
       "      <th>Chihuahua</th>\n",
       "      <td>2</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>White</th>\n",
       "      <th>St. Bernard</th>\n",
       "      <td>74</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Weight (kg)  Height(cm)\n",
       "Colour Breed                                \n",
       "Black  Labrador               29          59\n",
       "       Poodle                 23          43\n",
       "Brown  Labrador               25          56\n",
       "       Poodle                 22          46\n",
       "Gray   Schnauzer              17          49\n",
       "Tan    Chihuahua               2          18\n",
       "White  St. Bernard            74          77"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We can also group by multiple columns and aggregate by multiple columns.\n",
    "\n",
    "dogs.groupby(['Colour', 'Breed'])[[' Weight (kg)', 'Height(cm)']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9097747 0.0902253 0.       ]\n"
     ]
    }
   ],
   "source": [
    "# Calc total weekly sales \n",
    "sales_all = wallmart_df['weekly_sales'].sum()\n",
    "\n",
    "# Subset for type A stores, calc total weekly sales \n",
    "sales_A =  wallmart_df[wallmart_df['type'] == 'A' ]['weekly_sales'].sum()\n",
    "\n",
    "# Subset for type B stores, calc total weekly sales\n",
    "sales_B = wallmart_df[wallmart_df['type'] == 'B' ]['weekly_sales'].sum()\n",
    "\n",
    "# Subset for type C stores, calc total weekly sales\n",
    "sales_C = wallmart_df[wallmart_df['type'] == 'C' ]['weekly_sales'].sum()\n",
    "\n",
    "# Get proportion for each type \n",
    "sales_propn_by_type =  [sales_A, sales_B, sales_C] / sales_all\n",
    "\n",
    "print(sales_propn_by_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "type\n",
      "A    0.909775\n",
      "B    0.090225\n",
      "Name: weekly_sales, dtype: float64\n",
      "type  is_holiday\n",
      "A     False         2.336927e+08\n",
      "      True          2.360181e+04\n",
      "B     False         2.317678e+07\n",
      "      True          1.621410e+03\n",
      "Name: weekly_sales, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Group by type; calc total weekly sales\n",
    "sales_by_type = wallmart_df.groupby('type')['weekly_sales'].sum()\n",
    "\n",
    "# Get proportion for each type\n",
    "sales_propn_by_type =  sales_by_type / sum(sales_by_type)\n",
    "\n",
    "print(sales_propn_by_type)\n",
    "\n",
    "# Group by type and is_holiday; calc total weekly sales\n",
    "sales_by_type_is_holiday = wallmart_df.groupby(['type', 'is_holiday'])['weekly_sales'].sum()\n",
    "print(sales_by_type_is_holiday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        amin       amax          mean    median\n",
      "type                                           \n",
      "A    -1098.0  293966.05  23674.667242  11943.92\n",
      "B     -798.0  232558.51  25696.678370  13336.08\n",
      "     unemployment                         fuel_price_usd_per_l            \\\n",
      "             amin   amax      mean median                 amin      amax   \n",
      "type                                                                       \n",
      "A           3.879  8.992  7.972611  8.067             0.664129  1.107410   \n",
      "B           7.170  9.765  9.279323  9.199             0.760023  1.107674   \n",
      "\n",
      "                          \n",
      "          mean    median  \n",
      "type                      \n",
      "A     0.744619  0.735455  \n",
      "B     0.805858  0.803348  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devil\\AppData\\Local\\Temp\\ipykernel_19112\\3853719190.py:11: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  unemp_fuel_stats = wallmart_df.groupby('type')['unemployment', 'fuel_price_usd_per_l'].agg([np.min, np.max, np.mean, np.median])\n"
     ]
    }
   ],
   "source": [
    "# Ä±mport numpy with allias np \n",
    "import numpy as np \n",
    "\n",
    "# For each store type, aggregate weekly_sales: get min, max, mean and median\n",
    "sales_stats = wallmart_df.groupby('type')['weekly_sales'].agg([np.min, np.max, np.mean, np.median])\n",
    "\n",
    "# Print sale_stats \n",
    "print(sales_stats)\n",
    "\n",
    "# For each store type, aggregate unemployment and fuel_price_usd_per_l: get min, max, mean and median\n",
    "unemp_fuel_stats = wallmart_df.groupby('type')['unemployment', 'fuel_price_usd_per_l'].agg([np.min, np.max, np.mean, np.median])\n",
    "\n",
    "# Print unemp_fuel_stats\n",
    "print(unemp_fuel_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pivot Tables\n",
    "\n",
    "If you've ever used a spreadsheet, chances are you've used a pivot table. Let's see how to create pivot tables in pandas.\n",
    "\n",
    "In the last lesson, we grouped dogs by color and calculated their mean weights. We can do the same thing using the **pivot_table** method.  \n",
    "The **values** argument is the column that you want to summarize, and the **index** is the column that you want to group by. By default, pivot_table takes the **mean** value for each group.\n",
    "\n",
    "```python\t\n",
    "dogs.groupby('color')['weight_kg'].mean()\n",
    "```\n",
    "\n",
    "This is same as this:\n",
    "\n",
    "```python\n",
    "dogs.pivot_table(values='weight_kg', index='color', aggfunc='mean')\n",
    "```\n",
    "\n",
    "### Different statistics\n",
    "\n",
    "If we want a different summart statistic, we can use the **aggfunc** argument and pass it a function.\n",
    "\n",
    "```python\n",
    "dogs.pivot_table(values='weight_kg', index='color', aggfunc=np.median)\n",
    "```\n",
    "\n",
    "We can also pass multiple functions to aggfunc argument.\n",
    "\n",
    "```python\n",
    "dogs.pivot_table(values='weight_kg', index='color', aggfunc=[np.median, np.mean])\n",
    "```\n",
    "### Pivot on two variables\n",
    "\n",
    "We can also pivot on two different variables or columns\n",
    "\n",
    "```python\n",
    "dogs.groupby(['color', 'weight_kg'])['weight_kg'].mean()\n",
    "```\n",
    "\n",
    "```python\t\n",
    "dogs.pivot_table(values='weight_kg', index='color', columns='breed') \n",
    "```\n",
    "\n",
    "### Filling the missing values in pivot tables\n",
    "\n",
    "Instead of having lots of missing values in our pivot table, we can have them filled in using **fill_value** argument.\n",
    "\n",
    "```python\n",
    "dogs.pivot_table(values='weight_kg', index='color', columns='breed', fill_value=0)\n",
    "```\n",
    "\n",
    "### Summing with Pivot Tables\n",
    "\n",
    "If we set the margins argument to True, we can sum the values in the pivot table.\n",
    "\n",
    "```python\n",
    "dogs.pivot_table(values='weight_kg', index='color', columns='breed', margins=True)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      weekly_sales\n",
      "type              \n",
      "A     23674.667242\n",
      "B     25696.678370\n"
     ]
    }
   ],
   "source": [
    "# Pivot for mean weekly_sales for each store type \n",
    "mean_sales_by_type = wallmart_df.pivot_table(values='weekly_sales', index='type')\n",
    "\n",
    "# Print mean_sales_by_type\n",
    "print(mean_sales_by_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              mean       median\n",
      "      weekly_sales weekly_sales\n",
      "type                           \n",
      "A     23674.667242     11943.92\n",
      "B     25696.678370     13336.08\n"
     ]
    }
   ],
   "source": [
    "# Pivot for mean and median weekly_sales for each store type\n",
    "mean_med_sales_by_type = wallmart_df.pivot_table(values='weekly_sales', index='type', aggfunc=[np.mean, np.median])\n",
    "\n",
    "# Print mean_med_sales_by_type\n",
    "print(mean_med_sales_by_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "is_holiday         False      True \n",
      "type                               \n",
      "A           23768.583523  590.04525\n",
      "B           25751.980533  810.70500\n"
     ]
    }
   ],
   "source": [
    "# Pivot for mean weekly_sales by store type and holiday\n",
    "mean_sales_by_type_holiday = wallmart_df.pivot_table(values='weekly_sales', index='type', columns='is_holiday')\n",
    "\n",
    "# print mean_sales_by_type_holiday\n",
    "print(mean_sales_by_type_holiday)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "department            1              2             3             4   \\\n",
      "type                                                                  \n",
      "A           30961.725379   67600.158788  17160.002955  44285.399091   \n",
      "B           44050.626667  112958.526667  30580.655000  51219.654167   \n",
      "\n",
      "department            5             6             7             8   \\\n",
      "type                                                                 \n",
      "A           34821.011364   7136.292652  38454.336818  48583.475303   \n",
      "B           63236.875000  10717.297500  52909.653333  90733.753333   \n",
      "\n",
      "department            9             10  ...            90            91  \\\n",
      "type                                    ...                               \n",
      "A           30120.449924  30930.456364  ...  85776.905909  70423.165227   \n",
      "B           66679.301667  48595.126667  ...  14780.210000  13199.602500   \n",
      "\n",
      "department             92            93            94             95  \\\n",
      "type                                                                   \n",
      "A           139722.204773  53413.633939  60081.155303  123933.787121   \n",
      "B            50859.278333   1466.274167    161.445833   77082.102500   \n",
      "\n",
      "department            96            97            98          99  \n",
      "type                                                              \n",
      "A           21367.042857  28471.266970  12875.423182  379.123659  \n",
      "B            9528.538333   5828.873333    217.428333    0.000000  \n",
      "\n",
      "[2 rows x 80 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print mean weekly_sales by department and type; fill missing values with 0\n",
    "print(wallmart_df.pivot_table(values='weekly_sales', index='type', columns='department', fill_value=0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "department             1              2             3             4  \\\n",
      "type                                                                  \n",
      "A           30961.725379   67600.158788  17160.002955  44285.399091   \n",
      "B           44050.626667  112958.526667  30580.655000  51219.654167   \n",
      "All         32052.467153   71380.022778  18278.390625  44863.253681   \n",
      "\n",
      "department             5             6             7             8  \\\n",
      "type                                                                 \n",
      "A           34821.011364   7136.292652  38454.336818  48583.475303   \n",
      "B           63236.875000  10717.297500  52909.653333  90733.753333   \n",
      "All         37189.000000   7434.709722  39658.946528  52095.998472   \n",
      "\n",
      "department             9            10  ...            91             92  \\\n",
      "type                                    ...                                \n",
      "A           30120.449924  30930.456364  ...  70423.165227  139722.204773   \n",
      "B           66679.301667  48595.126667  ...  13199.602500   50859.278333   \n",
      "All         33167.020903  32402.512222  ...  65654.535000  132316.960903   \n",
      "\n",
      "department            93            94             95            96  \\\n",
      "type                                                                  \n",
      "A           53413.633939  60081.155303  123933.787121  21367.042857   \n",
      "B            1466.274167    161.445833   77082.102500   9528.538333   \n",
      "All         49084.687292  55087.846181  120029.480069  20337.607681   \n",
      "\n",
      "department            97            98          99           All  \n",
      "type                                                              \n",
      "A           28471.266970  12875.423182  379.123659  23674.667242  \n",
      "B            5828.873333    217.428333    0.000000  25696.678370  \n",
      "All         26584.400833  11820.590278  379.123659  23843.950149  \n",
      "\n",
      "[3 rows x 81 columns]\n"
     ]
    }
   ],
   "source": [
    "# Print the mean weekly_sales by department and type; fill missing values with 0s; sum all rows and cols \n",
    "print(wallmart_df.pivot_table(values='weekly_sales', index='type', columns='department', fill_value= 0, margins=True))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5ff4f941d0d24c2500e4628fe95d4ab1321bac2b4f224af3851b4dbd2aa6f6ec"
  },
  "kernelspec": {
   "display_name": "Python 3.9.6 ('py39')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
