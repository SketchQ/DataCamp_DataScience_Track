{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson I \n",
    "\n",
    "## Importing Flat Files From the Web\n",
    "\n",
    "We are now able to import data in Python from all sorts of file types:\n",
    "\n",
    "* Flat files: .txt, .csv\n",
    "* Pickled files, Excel Spreadsheets, and many others!\n",
    "* Data from relational databases\n",
    "\n",
    "However, all of these skill involve importing data from files that you have locally. What if your data is online?\n",
    "\n",
    "We can use our browser and navigate the relevant URL, and download the file but this poses a few problems:\n",
    "* It isn't written in code and so posses reproducibility\n",
    "* It is **NOT** scalable.\n",
    "\n",
    "### We'll learn how to...\n",
    "\n",
    "* Import and locally save datasets from the web\n",
    "* Load datasets into pandas DataFrames\n",
    "* Make HTTP requests (GET requests)\n",
    "* Scrape web data such as HTML\n",
    "* Parse HTML into useful data (BeautifulSoup)\n",
    "* Use the urllib and requests packages\n",
    "\n",
    "We'll first check out urllib:\n",
    "\n",
    "### The urllib package\n",
    "\n",
    "This module provides a high-level interface for fetching data across the World Wide Web, in particular, the ```urlopen()``` function is similiar to the built-in function ```open()```, but accepts Universal Resource Locators(URLs) instead of filenames.\n",
    "\n",
    "#### How to automate file download in Python\n",
    "\n",
    "```python\n",
    "from urllib.request import urlretrieve\n",
    "url = 'htttp://SOME--URL--.com'\n",
    "urlretrieve(url, 'winequality_white.csv')\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise Importing flat files from the web\n",
    "\n",
    "You are about to import your first file from the web! The flat file you will import will be ```'winequality-red.csv'``` from the University of California, Irvine's [Machine Learning repository](https://archive.ics.uci.edu/ml/index.php). The flat file contains tabular data of physiochemical properties of red wine, such as pH, alcohol content and citric acid content, along with wine quality rating.\n",
    "\n",
    "The URL of the file is:\n",
    "\n",
    "``` \n",
    "'https://assets.datacamp.com/production/course_1606/datasets/winequality-red.csv'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.4              0.70         0.00             1.9      0.076   \n",
      "1            7.8              0.88         0.00             2.6      0.098   \n",
      "2            7.8              0.76         0.04             2.3      0.092   \n",
      "3           11.2              0.28         0.56             1.9      0.075   \n",
      "4            7.4              0.70         0.00             1.9      0.076   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
      "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
      "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
      "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      9.4        5  \n",
      "1      9.8        5  \n",
      "2      9.8        5  \n",
      "3      9.8        6  \n",
      "4      9.4        5  \n"
     ]
    }
   ],
   "source": [
    "# Import package\n",
    "from urllib.request import urlretrieve\n",
    "\n",
    "# Import pandas\n",
    "import pandas as pd\n",
    "\n",
    "# Assign url of file : url\n",
    "url = 'https://assets.datacamp.com/production/course_1606/datasets/winequality-red.csv'\n",
    "\n",
    "# Save file locally\n",
    "urlretrieve(url, 'datasets/winequality-red.csv')\n",
    "\n",
    "# Read file into a DataFrame and print its head\n",
    "df = pd.read_csv('datasets/winequality-red.csv', sep=';')\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening and reading flat files from the web\n",
    "\n",
    "You have just imported a file from the web, saved it locally and loaded it into a DataFrame. If you just wanted to load a file from the web into a DataFrame without first saving it locally, you can do that easily using ```pandas```. In particular, you can use the function ```pd.read_csv()``` with the URL as the first argument and the separator ```sep``` as the second argument.\n",
    "\n",
    "The URL of the file, once again, is:\n",
    "\n",
    "```\n",
    "'https://assets.datacamp.com/production/course_1606/datasets/winequality-red.csv'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
      "0            7.4              0.70         0.00             1.9      0.076   \n",
      "1            7.8              0.88         0.00             2.6      0.098   \n",
      "2            7.8              0.76         0.04             2.3      0.092   \n",
      "3           11.2              0.28         0.56             1.9      0.075   \n",
      "4            7.4              0.70         0.00             1.9      0.076   \n",
      "\n",
      "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
      "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
      "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
      "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
      "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      9.4        5  \n",
      "1      9.8        5  \n",
      "2      9.8        5  \n",
      "3      9.8        6  \n",
      "4      9.4        5  \n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import packages\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# Assign url of file : url\n",
    "url = 'https://assets.datacamp.com/production/course_1606/datasets/winequality-red.csv'\n",
    "\n",
    "# Read file into a DataFrame: df\n",
    "df = pd.read_csv(url, sep=';')\n",
    "\n",
    "# Print the head of the DataFrame\n",
    "print(df.head())\n",
    "\n",
    "# Plot first column of df\n",
    "df.iloc[:, 0].hist()\n",
    "plt.xlabel('fixed acidity (g(tartaric acid)/ dm$^3$)')\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing non-flat files from the web\n",
    "\n",
    "Congrats! You've just loaded a flat file from the web into a DataFrame without first saving it locally using the ```pandas``` function ```pd.read_csv()```. This function is super cool because it has close relatives that allow you to load all types of files, not only flat ones. In this interactive exercise, you'll use ```pd.read_excel()``` to import an Excel spreadsheet.\n",
    "\n",
    "The URL of the spreadsheet is :\n",
    "\n",
    "```\n",
    "'https://assets.datacamp.com/course/importing_data_into_r/latitude.xls'\n",
    "```\n",
    "\n",
    "Your job is to use ```pd.read_excel()``` to read in all of its sheets, print the sheet names and then print the head of the first sheet using its name, not its index.\n",
    "\n",
    "Note that the output of ```pd.read_excel()``` is a Python dictionary with sheet names as keys and corresponding DataFrames as corresponding values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['1700', '1900'])\n",
      "                 country       1700\n",
      "0            Afghanistan  34.565000\n",
      "1  Akrotiri and Dhekelia  34.616667\n",
      "2                Albania  41.312000\n",
      "3                Algeria  36.720000\n",
      "4         American Samoa -14.307000\n"
     ]
    }
   ],
   "source": [
    "# Import package\n",
    "import pandas as pd\n",
    "\n",
    "# Assign url of file: url\n",
    "url = 'https://assets.datacamp.com/course/importing_data_into_r/latitude.xls'\n",
    "\n",
    "# Read in all sheets of Excel file: xls\n",
    "xls = pd.read_excel(url, sheet_name=None)\n",
    "\n",
    "# Print the sheetnames to the shell\n",
    "print(xls.keys())\n",
    "\n",
    "# Print the head of the first sheet (using its name, Not its index)\n",
    "print(xls['1700'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson II\n",
    "\n",
    "## HTTP requests to import files from the web\n",
    "\n",
    "### URL\n",
    "\n",
    "* URL Stands for Uniform or Universal Resource Locator\n",
    "* References to websources\n",
    "* URLs can refer to a few other things, but we will focus on web addresses\n",
    "* Locations of websites consists of 2 parts:\n",
    "    - Protocol identifier - http:\n",
    "    - Resource name - datacamp.com\n",
    "\n",
    "### HTTP\n",
    "\n",
    "* HTTP stands for HyperText Transfer Protocol\n",
    "* Foundation of data communication for the web\n",
    "* HTTPS - more secure form of HTTP\n",
    "* When we go to a website, we are actually sending HTTP request to a server\n",
    "    - Which is know by GET request\n",
    "* We are performing a GET request when using the function ```urlretrieve()```.\n",
    "* We will also figure out how to get HTML(HyperText Markup Language) from a webpage.\n",
    "\n",
    "### GET requests using urllib\n",
    "\n",
    "```python\n",
    "from urllib.request import urlopen, Request\n",
    "url = 'https://www.wikipedia.org/'\n",
    "request = Request(url)\n",
    "response = urlopen(request)\n",
    "html = response.read()\n",
    "response.close()\n",
    "```\n",
    "\n",
    "### GET requests using requests\n",
    "\n",
    "```python\n",
    "import requests\n",
    "url = 'https://www.wikipedia.org/'\n",
    "r = requests.get(url)\n",
    "text = r.text\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "### Performing HTTP requests in Python using urllib\n",
    "\n",
    "Now that you know the basics behind HTTP GET requests, it's time to perform some of your own. In this interactive exercise, you will ping our very own DataCamp servers to perform a GET request to extract information from the first coding exercise of this course,\n",
    "\n",
    "```\n",
    "\"https://campus.datacamp.com/courses/1606/4135?ex=2\"\n",
    "```\n",
    "\n",
    "In the next exercise, you'll extract the HTML itself. Right now, however, you are going to package and send the request and then catch the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'http.client.HTTPResponse'>\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "from urllib.request import urlopen, Request\n",
    "\n",
    "# Specify the URL\n",
    "url = \"https://campus.datacamp.com/courses/1606/4135?ex=2\"\n",
    "\n",
    "# This packages the request : request\n",
    "request = Request(url)\n",
    "\n",
    "# Sends the request and catches the response: response\n",
    "response = urlopen(request)\n",
    "\n",
    "# Print the datatype of response\n",
    "print(type(response))\n",
    "\n",
    "# Close the response\n",
    "response.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Printing HTTP requests results in Python using urllib\n",
    "\n",
    "You have just packaged and sent a **GET** request to: \n",
    "```\n",
    "\"https://campus.datacamp.com/courses/1606/4135?ex=2\" \n",
    "```\n",
    "and then caught the response. You saw that such a response is a ```http.client.HTTPResponse``` *object*. The question remains: what can you do with this response?\n",
    "\n",
    "Well, as it came from an HTML page, you could read it to extract the HTML and, in fact, such a ```http.client.HTTPResponse``` object has an associated ```read()``` method. In this exercise, you'll build on your previous great work to extract the response and print the HTML.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "from urllib.request import urlopen, Request\n",
    "\n",
    "# Specify the url\n",
    "url = \"https://campus.datacamp.com/courses/1606/4135?ex=2\"\n",
    "\n",
    "# this packages the request\n",
    "request = Request(url)\n",
    "\n",
    "# Sends the request and catches the response: response\n",
    "response = urlopen(request)\n",
    "\n",
    "# Extract the respone : html\n",
    "html = response.read()\n",
    "\n",
    "# print the html\n",
    "print(html)\n",
    "\n",
    "# Close the response\n",
    "response.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performing HTTP requests in Python using requests\n",
    "\n",
    "Now that you've got your head and hands around making HTTP requests using the urllib package, you're going to figure out how to do the same using the higher-level requests library. You'll once again be pinging DataCamp servers for their :\n",
    "```\n",
    "\"http://www.datacamp.com/teach/documentation\" \n",
    "```\n",
    "page.\n",
    "\n",
    "Note that unlike in the previous exercises using urllib, you don't have to close the connection when using requests!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import package\n",
    "import requests\n",
    "\n",
    "# Specify the url : url\n",
    "url = \"http://www.datacamp.com/teach/documentation\"\n",
    "\n",
    "# Packages the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Extract the response: text\n",
    "text = r.text\n",
    "\n",
    "# Print the html\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson III\n",
    "\n",
    "## Scraping the web in Python\n",
    "\n",
    "### HTML\n",
    "\n",
    "* HTML is a mix of unstructured and structured data\n",
    "\n",
    "* **Structured Data**:\n",
    "    - Has pre-defined data model, or\n",
    "    - Organized in a defined manner\n",
    "* **Unstructured Data**:\n",
    "    - Has neither of these properties\n",
    "\n",
    "HTML is interesting because, although much of it is unstructured text, it does contain tags that determine where, headings can be found, or hyperlinks.\n",
    "\n",
    "### BeatifulSoup\n",
    "\n",
    "To turn HTML that we have scraped from the web into useful data, we'll need to parse it and extract structured data from it.\n",
    "\n",
    "<img src='pictures/bs4.jpg' />\n",
    "\n",
    "In web development, the term *\"tag soup\"* refers to structurally or syntactically incorrect HTML code written for a web page. What does Beautiful Soup does best is to make tag soup beautiful again and to extract information from it with ease!\n",
    "\n",
    "```python\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "\n",
    "url='https://www.crummy.com/software/BeautifulSoup/'\n",
    "r = requests.get(url)\n",
    "html_doc = r.text\n",
    "soup = BeautifulSoup(html_doc)\n",
    "```\n",
    "\n",
    "```python\n",
    "print(soup.prettify())\n",
    "```\n",
    "\n",
    "Output will be indented in the way we would expect properly written HTML to be\n",
    "\n",
    "#### Exploring BeautifulSoup\n",
    "\n",
    "* Many Methods such as :\n",
    "    - ```print(soup.title)```\n",
    "    - ```print(soup.get_text())```\n",
    "\n",
    "* ```find_all()```\n",
    "    ```python\n",
    "    for link in soup.find_all('a'):\n",
    "        print(link.get('href'))\n",
    "    ```    \n",
    "    - Will find all the links in HTML file\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise\n",
    "\n",
    "### Parsing HTML with BeautifulSoup\n",
    "\n",
    "In this interactive exercise, you'll learn how to use the BeautifulSoup package to *parse*, *prettify* and *extract* information from HTML. You'll scrape the data from the webpage of Guido van Rossum, Python's very own [Benevolent Dictator for Life](https://en.wikipedia.org/wiki/Benevolent_dictator_for_life). In the following exercises, you'll prettify the HTML and then extract the text and the hyperlinks.\n",
    "\n",
    "The URL of interest is:\n",
    "\n",
    "```python\n",
    "url = 'https://www.python.org/~guido/'\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<html>\n",
      " <head>\n",
      "  <title>\n",
      "   Guido's Personal Home Page\n",
      "  </title>\n",
      " </head>\n",
      " <body bgcolor=\"#FFFFFF\" text=\"#000000\">\n",
      "  <!-- Built from main -->\n",
      "  <h1>\n",
      "   <a href=\"pics.html\">\n",
      "    <img border=\"0\" src=\"images/IMG_2192.jpg\"/>\n",
      "   </a>\n",
      "   Guido van Rossum - Personal Home Page\n",
      "   <a href=\"pics.html\">\n",
      "    <img border=\"0\" height=\"216\" src=\"images/guido-headshot-2019.jpg\" width=\"270\"/>\n",
      "   </a>\n",
      "  </h1>\n",
      "  <p>\n",
      "   <a href=\"http://www.washingtonpost.com/wp-srv/business/longterm/microsoft/stories/1998/raymond120398.htm\">\n",
      "    <i>\n",
      "     \"Gawky and proud of it.\"\n",
      "    </i>\n",
      "   </a>\n",
      "  </p>\n",
      "  <h3>\n",
      "   <a href=\"images/df20000406.jpg\">\n",
      "    Who I Am\n",
      "   </a>\n",
      "  </h3>\n",
      "  <p>\n",
      "   Read\n",
      "my\n",
      "   <a href=\"http://neopythonic.blogspot.com/2016/04/kings-day-speech.html\">\n",
      "    \"King's\n",
      "Day Speech\"\n",
      "   </a>\n",
      "   for some inspiration.\n",
      "  </p>\n",
      "  <p>\n",
      "   I am the author of the\n",
      "   <a href=\"http://www.python.org\">\n",
      "    Python\n",
      "   </a>\n",
      "   programming language.  See also my\n",
      "   <a href=\"Resume.html\">\n",
      "    resume\n",
      "   </a>\n",
      "   and my\n",
      "   <a href=\"Publications.html\">\n",
      "    publications list\n",
      "   </a>\n",
      "   , a\n",
      "   <a href=\"bio.html\">\n",
      "    brief bio\n",
      "   </a>\n",
      "   , assorted\n",
      "   <a href=\"http://legacy.python.org/doc/essays/\">\n",
      "    writings\n",
      "   </a>\n",
      "   ,\n",
      "   <a href=\"http://legacy.python.org/doc/essays/ppt/\">\n",
      "    presentations\n",
      "   </a>\n",
      "   and\n",
      "   <a href=\"interviews.html\">\n",
      "    interviews\n",
      "   </a>\n",
      "   (all about Python), some\n",
      "   <a href=\"pics.html\">\n",
      "    pictures of me\n",
      "   </a>\n",
      "   ,\n",
      "   <a href=\"http://neopythonic.blogspot.com\">\n",
      "    my new blog\n",
      "   </a>\n",
      "   , and\n",
      "my\n",
      "   <a href=\"http://www.artima.com/weblogs/index.jsp?blogger=12088\">\n",
      "    old\n",
      "blog\n",
      "   </a>\n",
      "   on Artima.com.  I am\n",
      "   <a href=\"https://twitter.com/gvanrossum\">\n",
      "    @gvanrossum\n",
      "   </a>\n",
      "   on Twitter.\n",
      "  </p>\n",
      "  <p>\n",
      "   I am currently a Distinguished Engineer at Microsoft.\n",
      "I have worked for Dropbox, Google, Elemental Security, Zope\n",
      "Corporation, BeOpen.com, CNRI, CWI, and SARA.  (See\n",
      "my\n",
      "   <a href=\"Resume.html\">\n",
      "    resume\n",
      "   </a>\n",
      "   .)  I created Python while at CWI.\n",
      "  </p>\n",
      "  <h3>\n",
      "   How to Reach Me\n",
      "  </h3>\n",
      "  <p>\n",
      "   You can send email for me to guido (at) python.org.\n",
      "I read everything sent there, but I receive too much email to respond\n",
      "to everything.\n",
      "  </p>\n",
      "  <h3>\n",
      "   My Name\n",
      "  </h3>\n",
      "  <p>\n",
      "   My name often poses difficulties for Americans.\n",
      "  </p>\n",
      "  <p>\n",
      "   <b>\n",
      "    Pronunciation:\n",
      "   </b>\n",
      "   in Dutch, the \"G\" in Guido is a hard G,\n",
      "pronounced roughly like the \"ch\" in Scottish \"loch\".  (Listen to the\n",
      "   <a href=\"guido.au\">\n",
      "    sound clip\n",
      "   </a>\n",
      "   .)  However, if you're\n",
      "American, you may also pronounce it as the Italian \"Guido\".  I'm not\n",
      "too worried about the associations with mob assassins that some people\n",
      "have. :-)\n",
      "  </p>\n",
      "  <p>\n",
      "   <b>\n",
      "    Spelling:\n",
      "   </b>\n",
      "   my last name is two words, and I'd like to keep it\n",
      "that way, the spelling on some of my credit cards notwithstanding.\n",
      "Dutch spelling rules dictate that when used in combination with my\n",
      "first name, \"van\" is not capitalized: \"Guido van Rossum\".  But when my\n",
      "last name is used alone to refer to me, it is capitalized, for\n",
      "example: \"As usual, Van Rossum was right.\"\n",
      "  </p>\n",
      "  <p>\n",
      "   <b>\n",
      "    Alphabetization:\n",
      "   </b>\n",
      "   in America, I show up in the alphabet under\n",
      "\"V\".  But in Europe, I show up under \"R\".  And some of my friends put\n",
      "me under \"G\" in their address book...\n",
      "  </p>\n",
      "  <h3>\n",
      "   More Hyperlinks\n",
      "  </h3>\n",
      "  <ul>\n",
      "   <li>\n",
      "    Here's a collection of\n",
      "    <a href=\"http://legacy.python.org/doc/essays/\">\n",
      "     essays\n",
      "    </a>\n",
      "    relating to Python\n",
      "that I've written, including the foreword I wrote for Mark Lutz' book\n",
      "\"Programming Python\".\n",
      "    <p>\n",
      "    </p>\n",
      "   </li>\n",
      "   <li>\n",
      "    I own the official\n",
      "    <a href=\"images/license.jpg\">\n",
      "     <img align=\"center\" border=\"0\" height=\"75\" src=\"images/license_thumb.jpg\" width=\"100\"/>\n",
      "     Python license.\n",
      "    </a>\n",
      "    <p>\n",
      "    </p>\n",
      "   </li>\n",
      "  </ul>\n",
      "  <h3>\n",
      "   The Audio File Formats FAQ\n",
      "  </h3>\n",
      "  <p>\n",
      "   I was the original creator and maintainer of the Audio File Formats\n",
      "FAQ.  It is now maintained by Chris Bagwell\n",
      "at\n",
      "   <a href=\"http://www.cnpbagwell.com/audio-faq\">\n",
      "    http://www.cnpbagwell.com/audio-faq\n",
      "   </a>\n",
      "   .  And here is a link to\n",
      "   <a href=\"http://sox.sourceforge.net/\">\n",
      "    SOX\n",
      "   </a>\n",
      "   , to which I contributed\n",
      "some early code.\n",
      "  </p>\n",
      "  <hr/>\n",
      "  <a href=\"images/internetdog.gif\">\n",
      "   \"On the Internet, nobody knows you're\n",
      "a dog.\"\n",
      "  </a>\n",
      "  <hr/>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Specify url: url\n",
    "url = 'https://www.python.org/~guido/'\n",
    "\n",
    "# Package the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Extracts the response as html: html_doc\n",
    "html_doc = r.text\n",
    "\n",
    "# Create a BeautifulSoup object from the HTML: soup\n",
    "soup = BeautifulSoup(html_doc)\n",
    "\n",
    "# Prettify the BeautifulSoup object: pretty_soup\n",
    "pretty_soup = soup.prettify()\n",
    "\n",
    "# Print the response\n",
    "print(pretty_soup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turning a webpage into data using BeautifulSoup: getting the text\n",
    "\n",
    "As promised, in the following exercises, you'll learn the basics of extracting information from HTML soup. In this exercise, you'll figure out how to extract the text from the BDFL's webpage, along with printing the webpage's title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Guido's Personal Home Page</title>\n",
      "\n",
      "\n",
      "Guido's Personal Home Page\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Guido van Rossum - Personal Home Page\n",
      "\n",
      "\n",
      "\"Gawky and proud of it.\"\n",
      "Who I Am\n",
      "Read\n",
      "my \"King's\n",
      "Day Speech\" for some inspiration.\n",
      "\n",
      "I am the author of the Python\n",
      "programming language.  See also my resume\n",
      "and my publications list, a brief bio, assorted writings, presentations and interviews (all about Python), some\n",
      "pictures of me,\n",
      "my new blog, and\n",
      "my old\n",
      "blog on Artima.com.  I am\n",
      "@gvanrossum on Twitter.\n",
      "\n",
      "I am currently a Distinguished Engineer at Microsoft.\n",
      "I have worked for Dropbox, Google, Elemental Security, Zope\n",
      "Corporation, BeOpen.com, CNRI, CWI, and SARA.  (See\n",
      "my resume.)  I created Python while at CWI.\n",
      "\n",
      "How to Reach Me\n",
      "You can send email for me to guido (at) python.org.\n",
      "I read everything sent there, but I receive too much email to respond\n",
      "to everything.\n",
      "\n",
      "My Name\n",
      "My name often poses difficulties for Americans.\n",
      "\n",
      "Pronunciation: in Dutch, the \"G\" in Guido is a hard G,\n",
      "pronounced roughly like the \"ch\" in Scottish \"loch\".  (Listen to the\n",
      "sound clip.)  However, if you're\n",
      "American, you may also pronounce it as the Italian \"Guido\".  I'm not\n",
      "too worried about the associations with mob assassins that some people\n",
      "have. :-)\n",
      "\n",
      "Spelling: my last name is two words, and I'd like to keep it\n",
      "that way, the spelling on some of my credit cards notwithstanding.\n",
      "Dutch spelling rules dictate that when used in combination with my\n",
      "first name, \"van\" is not capitalized: \"Guido van Rossum\".  But when my\n",
      "last name is used alone to refer to me, it is capitalized, for\n",
      "example: \"As usual, Van Rossum was right.\"\n",
      "\n",
      "Alphabetization: in America, I show up in the alphabet under\n",
      "\"V\".  But in Europe, I show up under \"R\".  And some of my friends put\n",
      "me under \"G\" in their address book...\n",
      "\n",
      "\n",
      "More Hyperlinks\n",
      "\n",
      "Here's a collection of essays relating to Python\n",
      "that I've written, including the foreword I wrote for Mark Lutz' book\n",
      "\"Programming Python\".\n",
      "I own the official \n",
      "Python license.\n",
      "\n",
      "The Audio File Formats FAQ\n",
      "I was the original creator and maintainer of the Audio File Formats\n",
      "FAQ.  It is now maintained by Chris Bagwell\n",
      "at http://www.cnpbagwell.com/audio-faq.  And here is a link to\n",
      "SOX, to which I contributed\n",
      "some early code.\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\"On the Internet, nobody knows you're\n",
      "a dog.\"\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Specify url: url\n",
    "url = 'https://www.python.org/~guido/'\n",
    "\n",
    "# Package the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Extract the response as html: html_doc\n",
    "html_doc = r.text\n",
    "\n",
    "# Create a BeautifulSoup object from the HTML: soup\n",
    "soup = BeautifulSoup(html_doc)\n",
    "\n",
    "# Get the title of Guido's webpage: guido_title\n",
    "guido_title = soup.title\n",
    "\n",
    "# Print the title of Guio's webpage to the shell\n",
    "print(guido_title)\n",
    "\n",
    "# Get Guido's text: guido_text\n",
    "guido_text = soup.get_text()\n",
    "\n",
    "# print Guido's text to the shell\n",
    "print(guido_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turning a webpage into data using BeautifulSoup: getting the hyperlinks\n",
    "\n",
    "In this exercise, you'll figure out how to extract the URLs of the hyperlinks from the BDFL's webpage. In the process, you'll become close friends with the soup method ```find_all()```."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>Guido's Personal Home Page</title>\n",
      "pics.html\n",
      "pics.html\n",
      "http://www.washingtonpost.com/wp-srv/business/longterm/microsoft/stories/1998/raymond120398.htm\n",
      "images/df20000406.jpg\n",
      "http://neopythonic.blogspot.com/2016/04/kings-day-speech.html\n",
      "http://www.python.org\n",
      "Resume.html\n",
      "Publications.html\n",
      "bio.html\n",
      "http://legacy.python.org/doc/essays/\n",
      "http://legacy.python.org/doc/essays/ppt/\n",
      "interviews.html\n",
      "pics.html\n",
      "http://neopythonic.blogspot.com\n",
      "http://www.artima.com/weblogs/index.jsp?blogger=12088\n",
      "https://twitter.com/gvanrossum\n",
      "Resume.html\n",
      "guido.au\n",
      "http://legacy.python.org/doc/essays/\n",
      "images/license.jpg\n",
      "http://www.cnpbagwell.com/audio-faq\n",
      "http://sox.sourceforge.net/\n",
      "images/internetdog.gif\n"
     ]
    }
   ],
   "source": [
    "# Import packages\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# Specify url\n",
    "url = 'https://www.python.org/~guido/'\n",
    "\n",
    "# Package the request, send the request and catch the response: r\n",
    "r = requests.get(url)\n",
    "\n",
    "# Extracts the response as html: html_doc\n",
    "html_doc = r.text\n",
    "\n",
    "# create a BeautifulSoup object from the HTML: soup\n",
    "soup = BeautifulSoup(html_doc)\n",
    "\n",
    "# Print the title of Guido's webpage\n",
    "print(soup.title)\n",
    "\n",
    "# Find all 'a' tags (which define hyperlinks): a_tags\n",
    "a_tags = soup.find_all('a')\n",
    "\n",
    "# Print the URLs to the shell\n",
    "for link in a_tags:\n",
    "    print(link.get('href'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4c59e6e5379e7fd956ce48a476e9664867cfb6229c9530fa6fd87fb84f21040f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
